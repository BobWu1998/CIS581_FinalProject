{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face Swap ver2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# This code does face swapping without skin color of source videos changed \n","\n"],"metadata":{"id":"JMFPGl07yRdI"}},{"cell_type":"markdown","source":["## How to use this code:\n","1. Use `cd` command to change to the location where you store the test videos\n","2. Change `source_name` and `target_name` to the names original videos you want to use as source and target.\n","3. Change `source_path` and `target_path` to folders where you want to save the extracted source images and target images from the original videos.\n","4. Change `predictor_path` to where you store the landmark detection training dataset.\n","5. Change `result_img_path` to where you want to store the resulting images.\n","6. Change `result_video_path` to where you want the output videos be.\n","\n"],"metadata":{"id":"8HRMBJ1urkuK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2u6DDPqm3ce","executionInfo":{"status":"ok","timestamp":1639800991493,"user_tz":300,"elapsed":15354,"user":{"displayName":"Bo Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01130970358551573333"}},"outputId":"deeb2806-8167-466d-fc60-fab9653f1a79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd /content/drive/Shareddrives/CIS581 Final Project/Notebook/BoWu/videos"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRCqY6EunRqL","executionInfo":{"status":"ok","timestamp":1639800992622,"user_tz":300,"elapsed":1133,"user":{"displayName":"Bo Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01130970358551573333"}},"outputId":"3a3d42b4-9746-478b-ea17-36f492bb54a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/CIS581 Final Project/Notebook/BoWu/videos\n"]}]},{"cell_type":"markdown","source":["# Define all the folder paths"],"metadata":{"id":"U-D_TX4XMcHa"}},{"cell_type":"code","source":["source_path = '/content/drive/Shareddrives/CIS581 Final Project/Notebook/BoWu/Source' # the folder where the source image you want to save to\n","target_path = '/content/drive/Shareddrives/CIS581 Final Project/Notebook/BoWu/Target' # the folder where the target image you want to save to\n","source_name = 'MrRobot.mp4' # name of source video\n","target_name = 'FrankUnderwood.mp4' # name of target video"],"metadata":{"id":"EgtSH25tnyV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictor_path = '/content/drive/Shareddrives/CIS581 Final Project/Notebook/BoWu/shape_predictor_68_face_landmarks.dat' # path of the face predictor\n","result_img_path = '/content/drive/Shareddrives/CIS581 Final Project/Notebook/BoWu/result_img' # save the image result after warping\n","result_video_path = '/content/drive/Shareddrives/CIS581 Final Project/Notebook/BoWu/result_video' # save the video after putting images together"],"metadata":{"id":"y0mS8lJjbqGn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get the image from source and target videos"],"metadata":{"id":"7Lb6SpgeKkKA"}},{"cell_type":"code","source":["import cv2\n"," \n","# Opens the inbuilt camera of laptop to capture video.\n","source_cap = cv2.VideoCapture(source_name)\n","target_cap = cv2.VideoCapture(target_name)\n","# Get FPS of current video\n","current_FPS = source_cap.get(cv2.CAP_PROP_FPS)\n","print('Current FPS of video:', current_FPS)\n","# Set Target FPS you want, must 30, 60, or 120\n","target_FPS = current_FPS ### Change this\n","fold = current_FPS//target_FPS\n","i = 0\n","count = 0\n","\n","while(source_cap.isOpened()):\n","    ret, frame = source_cap.read()\n","    # This condition prevents from infinite looping\n","    # incase video ends.\n","    if ret == False:\n","        break\n","    # Save Frame by Frame into disk using imwrite method\n","    if fold == 0:\n","      cv2.imwrite(source_path + '/Frame'+ str(i) +'.jpg', frame)\n","      count += 1\n","    else:\n","      if i%fold==0:\n","        cv2.imwrite(source_path +'/Frame'+ str(int(i/fold)) +'.jpg', frame)\n","        count += 1\n","    i += 1\n","print(\"total output frames of source video:\", count)\n","source_cap.release()\n","cv2.destroyAllWindows()\n","\n","source_count = count\n","\n","i = 0\n","count = 0\n","\n","while(target_cap.isOpened()):\n","    ret, frame = target_cap.read()\n","    # This condition prevents from infinite looping\n","    # incase video ends.\n","    if ret == False:\n","        break\n","    # Save Frame by Frame into disk using imwrite method\n","    if fold == 0:\n","      cv2.imwrite(target_path + '/Frame'+ str(i) +'.jpg', frame)\n","      count += 1\n","    else:\n","      if i%fold==0:\n","        cv2.imwrite(target_path +'/Frame'+ str(int(i/fold)) +'.jpg', frame)\n","        count += 1\n","    i += 1\n","print(\"total output frames of target video:\", count)\n","target_cap.release()\n","cv2.destroyAllWindows()\n","target_count = count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PSuMobkjnVYJ","executionInfo":{"status":"ok","timestamp":1639801183488,"user_tz":300,"elapsed":190867,"user":{"displayName":"Bo Wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01130970358551573333"}},"outputId":"f5bf6531-a7b6-484f-bcad-dda412824f36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current FPS of video: 25.0\n","total output frames of source video: 238\n","total output frames of target video: 223\n"]}]},{"cell_type":"markdown","source":["# Landmark Detection"],"metadata":{"id":"OiaLeuY2M6g_"}},{"cell_type":"code","source":["def landmarkDetection(image, predictor_path):\n","  '''\n","  INPUT:\n","  image = cv2.imread('/PATH/Image.jpg')\n","\n","  OUTPUT:\n","  image: Original image with 68 landmarks plotted\n","  shape (68,2): All landmark points\n","  '''\n","\n","  # initialize dlib's face detector (HOG-based) and then create\n","  # the facial landmark predictor\n","  p = \"shape_predictor_68_face_landmarks.dat\"\n","  detector = dlib.get_frontal_face_detector()\n","  predictor = dlib.shape_predictor(predictor_path)\n","\n","  # Convert image to grayscale for landmark detection\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # detect faces in the grayscale image\n","  rects = detector(gray, 0)\n","\n","  # loop over the face detections\n","  for (i, rect) in enumerate(rects):\n","    # determine the facial landmarks for the face region, then\n","    # convert the facial landmark (x, y)-coordinates to a NumPy\n","    # array\n","    shape = predictor(gray, rect)\n","    shape = face_utils.shape_to_np(shape)\n","        \n","    # loop over the (x, y)-coordinates for the facial landmarks\n","    # and draw them on the image\n","    # for (x, y) in shape:\n","    #   cv2.circle(image, (x, y), 2, (0, 255, 0), 2) # cv2.circle(image, center_coordinates, radius, color, thickness)\n","      \n","    # show the output image with the face detections + facial landmarks\n","    # result = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    return shape"],"metadata":{"id":"3HfISPNFcWYb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define heleper functions needed for triangulation and swapping"],"metadata":{"id":"lzYvZkrVMxrW"}},{"cell_type":"code","source":["from imutils import face_utils\n","import numpy as np\n","import dlib\n","import cv2\n","import matplotlib.pyplot as plt\n","from scipy.spatial import Delaunay\n","\n","# Read points from text file\n","def readPoints(path):\n","    # Create an array of points.\n","    points = [];\n","    \n","    # Read points\n","    with open(path) as file :\n","        for line in file :\n","            x, y = line.split()\n","            points.append((int(x), int(y)))\n","    \n","\n","    return points\n","\n","# Apply affine transform calculated using srcTri and dstTri to src and\n","# output an image of size.\n","def applyAffineTransform(src, srcTri, dstTri, size) :\n","    \n","    # Given a pair of triangles, find the affine transform.\n","    warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )\n","    \n","    # Apply the Affine Transform just found to the src image\n","    dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n","\n","    return dst\n","\n","\n","# Check if a point is inside a rectangle\n","def rectContains(rect, point) :\n","    if point[0] < rect[0] :\n","        return False\n","    elif point[1] < rect[1] :\n","        return False\n","    elif point[0] > rect[0] + rect[2] :\n","        return False\n","    elif point[1] > rect[1] + rect[3] :\n","        return False\n","    return True\n","\n","\n","#calculate delanauy triangle\n","def calculateDelaunayTriangles(rect, points):\n","    #create subdiv\n","    subdiv = cv2.Subdiv2D(rect);\n","    \n","    # Insert points into subdiv\n","    for p in points:\n","        subdiv.insert(p)\n","    \n","    triangleList = subdiv.getTriangleList();\n","\n","    print(subdiv)\n","\n","\n","    delaunayTri = []\n","    \n","    pt = []    \n","        \n","    for t in triangleList:        \n","        pt.append((t[0], t[1]))\n","        pt.append((t[2], t[3]))\n","        pt.append((t[4], t[5]))\n","        \n","        pt1 = (t[0], t[1])\n","        pt2 = (t[2], t[3])\n","        pt3 = (t[4], t[5])        \n","        \n","        if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n","            ind = []\n","            #Get face-points (from 68 face detector) by coordinates\n","            for j in range(0, 3):\n","                for k in range(0, len(points)):                    \n","                    if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n","                        ind.append(k)    \n","            # Three points form a triangle. Triangle array corresponds to the file tri.txt in FaceMorph \n","            if len(ind) == 3:                                                \n","                delaunayTri.append((ind[0], ind[1], ind[2]))\n","        \n","        pt = []        \n","            \n","    \n","    return delaunayTri\n","        \n","\n","# Warps and alpha blends triangular regions from img1 and img2 to img\n","def warpTriangle(img1, img2, t1, t2) :\n","    # Find bounding rectangle for each triangle\n","    r1 = cv2.boundingRect(np.float32([t1]))\n","    r2 = cv2.boundingRect(np.float32([t2]))\n","\n","    # Offset points by left top corner of the respective rectangles\n","    t1Rect = [] \n","    t2Rect = []\n","    t2RectInt = []\n","\n","    for i in range(0, 3):\n","        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n","        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n","        t2RectInt.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n","\n","\n","    # Get mask by filling triangle\n","    mask = np.zeros((r2[3], r2[2], 3), dtype = np.float32)\n","    cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0);\n","    \n","    # Apply warpImage to small rectangular patches\n","    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n","    #img2Rect = np.zeros((r2[3], r2[2]), dtype = img1Rect.dtype)\n","    \n","    size = (r2[2], r2[3])\n","\n","    img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n","    \n","    img2Rect = img2Rect * mask\n","\n","    # Copy triangular region of the rectangular patch to the output image\n","    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( (1.0, 1.0, 1.0) - mask )\n","     \n","    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect \n","        "],"metadata":{"id":"9ZL3-gMLcUdj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The swapping function for img1 and 2"],"metadata":{"id":"3hEUOdnmM-l6"}},{"cell_type":"code","source":["def mainTran(img1, img2, ith, old_hull2, old_img2):\n","    img1Warped = np.copy(img2);    \n","    \n","    points1 = landmarkDetection(img1, predictor_path)\n","    points2 = landmarkDetection(img2, predictor_path)\n","    \n","    # Find convex hull\n","    hull1 = []\n","    hull2 = []\n","\n","    original_hull_index = cv2.convexHull(np.array(points1), returnPoints = False) ### remember to change this points2\n","    # print(hullIndex)\n","    mouth_points = [\n","    # [48],  # <outer mouth>\n","    # [49],\n","    # [50],\n","    # [51],\n","    # [52],\n","    # [53],\n","    # [54],\n","    # [55],\n","    # [56],\n","    # [57],\n","    # [58],  # </outer mouth>\n","    [60],  # <inner mouth>\n","    [61],\n","    [62],\n","    [63],\n","    [64],\n","    [65],\n","    [66],\n","    [67],  # </inner mouth>\n","    ]\n","    hull_index = np.concatenate((original_hull_index, mouth_points))\n","          \n","    for i in range(0, len(hullIndex)):\n","        hull1.append(points1[int(hullIndex[i])])\n","        hull2.append(points2[int(hullIndex[i])])\n","\n","    original_hull2 = []\n","    for i in range(0, len(original_hull_index)):\n","      original_hull2.append(points2[int(original_hull_index[i])])\n","    \n","  ########### Apply Optical Flow\n","    old_hull2 = np.array(old_hull2, np.float32)\n","    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","    img2_gray_prev = cv2.cvtColor(old_img2, cv2.COLOR_BGR2GRAY)\n","\n","    hull2_next, *_ = cv2.calcOpticalFlowPyrLK(\n","            img2_gray_prev,\n","            img2_gray,\n","            old_hull2,\n","            np.array(hull2, np.float32),\n","            winSize=(101, 101),\n","            maxLevel=5,\n","            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.001),\n","            )\n","    for i, _ in enumerate(hull2):\n","        if i < len(hull2_next):\n","          hull2[i] = 0.3 * np.array(hull2[i]) + 0.7 * hull2_next[i]\n","\n","\n","    \n","  ###########\n","\n","    # Find delanauy traingulation for convex hull points\n","    sizeImg2 = img2.shape    \n","    rect = (0, 0, sizeImg2[1], sizeImg2[0])\n","     \n","    # dt = calculateDelaunayTriangles(rect, hull2)\n","    dt = Delaunay(np.array(hull1))\n","\n","    dt = dt.simplices\n","    if len(dt) == 0:\n","        quit()\n","    \n","    # Apply affine transformation to Delaunay triangles\n","    for i in range(0, len(dt)):\n","        t1 = []\n","        t2 = []\n","        \n","        #get points for img1, img2 corresponding to the triangles\n","        for j in range(0, 3):\n","            t1.append(hull1[dt[i][j]])\n","            t2.append(hull2[dt[i][j]])\n","        \n","        warpTriangle(img1, img1Warped, t1, t2)\n","    \n","            \n","    # Calculate Mask\n","    hull8U = []\n","    for i in range(0, len(original_hull2)):\n","        hull8U.append((original_hull2[i][0], original_hull2[i][1]))\n","    \n","    mask = np.zeros(img2.shape, dtype = img2.dtype)  \n","    \n","    cv2.fillConvexPoly(mask, np.int32(hull8U), (255, 255, 255))\n","    \n","    r = cv2.boundingRect(np.float32([original_hull2]))    \n","    \n","    center = ((r[0]+int(r[2]/2), r[1]+int(r[3]/2)))\n","    \n","    # Clone seamlessly.\n","    output = cv2.seamlessClone(np.uint8(img1Warped), img2, mask, center, cv2.NORMAL_CLONE)\n","    # output = correct_colours(output, img2, points2)\n","    # result = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n","    cv2.imwrite(result_img_path + '/' + str(ith) + '.jpg', output)\n","\n","    old_hull2 = hull2\n","    old_img2 = img2\n","    return old_hull2, old_img2"],"metadata":{"id":"L7Mr2-e5cYgp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main function you need to run for the image swapping"],"metadata":{"id":"JCAnFk-NNEwJ"}},{"cell_type":"markdown","source":["# Initialize the old_hull"],"metadata":{"id":"sCFcS3y66qt6"}},{"cell_type":"code","source":["old_img2 = cv2.imread(target_path + '/Frame' + str(1) + '.jpg')\n","old_hull2 = []\n","\n","points2 = landmarkDetection(old_img2, predictor_path)\n","\n","hullIndex = cv2.convexHull(np.array(points2), returnPoints = False)\n","    # print(hullIndex)\n","          \n","for i in range(0, len(hullIndex)):\n","    old_hull2.append(points2[int(hullIndex[i])])\n","old_hull2 = np.array(old_hull2, np.float32)"],"metadata":{"id":"4lWRBosu548B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_Image = 2 #min(source_count, target_count) # this is the total number of images you want use to reconstruct the video\n","\n","for i in range(1, n_Image):\n","    target_img = cv2.imread(target_path + '/Frame' + str(i) + '.jpg')\n","    source_img = cv2.imread(source_path + '/Frame' + str(i) + '.jpg')\n","    \n","    old_hull2, old_img2 = mainTran(source_img, target_img, i, old_hull2, old_img2)"],"metadata":{"id":"LhPPKN2acaVl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Video reconstruction from images"],"metadata":{"id":"g-WhotuBNK6c"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import glob\n","\n","\n","img_array = []\n","\n","for filename in glob.glob(result_img_path+'/*.jpg'):\n","    img = cv2.imread(filename)\n","    height, width, layers = img.shape\n","    size = (width,height)\n","    img_array.append(img)\n","\n","out = cv2.VideoWriter(result_video_path + '/project_of.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n"," \n","for i in range(len(img_array)):\n","    out.write(img_array[i])\n","out.release()"],"metadata":{"id":"mALLOl3JeyZz"},"execution_count":null,"outputs":[]}]}